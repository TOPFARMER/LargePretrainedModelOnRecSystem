{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_HR@5</th>\n",
       "      <th>val_NDCG@5</th>\n",
       "      <th>val_MRR@5</th>\n",
       "      <th>val_HR@10</th>\n",
       "      <th>val_NDCG@10</th>\n",
       "      <th>val_MRR@10</th>\n",
       "      <th>val_HR@20</th>\n",
       "      <th>val_NDCG@20</th>\n",
       "      <th>val_MRR@20</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060105</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>0.042704</td>\n",
       "      <td>0.087249</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>0.042704</td>\n",
       "      <td>0.142564</td>\n",
       "      <td>0.064117</td>\n",
       "      <td>0.042704</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>6.541750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.056998</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.070710</td>\n",
       "      <td>0.056998</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.084537</td>\n",
       "      <td>0.056998</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>5.938770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088504</td>\n",
       "      <td>0.058479</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>0.197194</td>\n",
       "      <td>0.088956</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>2</td>\n",
       "      <td>3275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3275</td>\n",
       "      <td>5.712047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.064412</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.145187</td>\n",
       "      <td>0.079893</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.217495</td>\n",
       "      <td>0.098070</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>3</td>\n",
       "      <td>4367</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4367</td>\n",
       "      <td>5.503188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.106182</td>\n",
       "      <td>0.070787</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>0.160812</td>\n",
       "      <td>0.088318</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>0.240990</td>\n",
       "      <td>0.108425</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>4</td>\n",
       "      <td>5459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5459</td>\n",
       "      <td>5.342911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.110287</td>\n",
       "      <td>0.073709</td>\n",
       "      <td>0.075088</td>\n",
       "      <td>0.170849</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.075088</td>\n",
       "      <td>0.250570</td>\n",
       "      <td>0.113162</td>\n",
       "      <td>0.075088</td>\n",
       "      <td>5</td>\n",
       "      <td>6551</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6551</td>\n",
       "      <td>5.218508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.119183</td>\n",
       "      <td>0.078556</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.179859</td>\n",
       "      <td>0.097963</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.264599</td>\n",
       "      <td>0.119274</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>6</td>\n",
       "      <td>7643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7643</td>\n",
       "      <td>5.121842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.121350</td>\n",
       "      <td>0.079945</td>\n",
       "      <td>0.080079</td>\n",
       "      <td>0.182140</td>\n",
       "      <td>0.099461</td>\n",
       "      <td>0.080079</td>\n",
       "      <td>0.265853</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.080079</td>\n",
       "      <td>7</td>\n",
       "      <td>8735</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>8735</td>\n",
       "      <td>5.045141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.123061</td>\n",
       "      <td>0.081673</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.102420</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.269161</td>\n",
       "      <td>0.122952</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>8</td>\n",
       "      <td>9827</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>9827</td>\n",
       "      <td>4.980723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.127623</td>\n",
       "      <td>0.083857</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>0.190579</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>9</td>\n",
       "      <td>10919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>10919</td>\n",
       "      <td>4.924483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.127167</td>\n",
       "      <td>0.084411</td>\n",
       "      <td>0.084870</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>0.084870</td>\n",
       "      <td>0.277828</td>\n",
       "      <td>0.126913</td>\n",
       "      <td>0.084870</td>\n",
       "      <td>10</td>\n",
       "      <td>12011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>12011</td>\n",
       "      <td>4.873684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.129106</td>\n",
       "      <td>0.085237</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.192860</td>\n",
       "      <td>0.105827</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.275890</td>\n",
       "      <td>0.126771</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>11</td>\n",
       "      <td>13103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>13103</td>\n",
       "      <td>4.827008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.129904</td>\n",
       "      <td>0.086361</td>\n",
       "      <td>0.086534</td>\n",
       "      <td>0.197993</td>\n",
       "      <td>0.108157</td>\n",
       "      <td>0.086534</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.128744</td>\n",
       "      <td>0.086534</td>\n",
       "      <td>12</td>\n",
       "      <td>14195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>14195</td>\n",
       "      <td>4.782851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.132641</td>\n",
       "      <td>0.088013</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>0.197879</td>\n",
       "      <td>0.109019</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>0.284215</td>\n",
       "      <td>0.130767</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>13</td>\n",
       "      <td>15287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>15287</td>\n",
       "      <td>4.740730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.133554</td>\n",
       "      <td>0.088775</td>\n",
       "      <td>0.088572</td>\n",
       "      <td>0.200958</td>\n",
       "      <td>0.110327</td>\n",
       "      <td>0.088572</td>\n",
       "      <td>0.283759</td>\n",
       "      <td>0.131186</td>\n",
       "      <td>0.088572</td>\n",
       "      <td>14</td>\n",
       "      <td>16379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>16379</td>\n",
       "      <td>4.699575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.134352</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.087630</td>\n",
       "      <td>0.200730</td>\n",
       "      <td>0.109422</td>\n",
       "      <td>0.087630</td>\n",
       "      <td>0.287181</td>\n",
       "      <td>0.131147</td>\n",
       "      <td>0.087630</td>\n",
       "      <td>15</td>\n",
       "      <td>17471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>17471</td>\n",
       "      <td>4.659648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.135835</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.089987</td>\n",
       "      <td>0.204151</td>\n",
       "      <td>0.111981</td>\n",
       "      <td>0.089987</td>\n",
       "      <td>0.290488</td>\n",
       "      <td>0.133739</td>\n",
       "      <td>0.089987</td>\n",
       "      <td>16</td>\n",
       "      <td>18563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>18563</td>\n",
       "      <td>4.620633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.137660</td>\n",
       "      <td>0.091827</td>\n",
       "      <td>0.091658</td>\n",
       "      <td>0.205064</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>0.091658</td>\n",
       "      <td>0.293339</td>\n",
       "      <td>0.135651</td>\n",
       "      <td>0.091658</td>\n",
       "      <td>17</td>\n",
       "      <td>19655</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>19655</td>\n",
       "      <td>4.581921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.137318</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>0.090544</td>\n",
       "      <td>0.205520</td>\n",
       "      <td>0.112684</td>\n",
       "      <td>0.090544</td>\n",
       "      <td>0.293910</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>0.090544</td>\n",
       "      <td>18</td>\n",
       "      <td>20747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>20747</td>\n",
       "      <td>4.544464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.138116</td>\n",
       "      <td>0.092159</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.294024</td>\n",
       "      <td>0.136175</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>19</td>\n",
       "      <td>21839</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>21839</td>\n",
       "      <td>4.507083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.136633</td>\n",
       "      <td>0.091512</td>\n",
       "      <td>0.091622</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.113191</td>\n",
       "      <td>0.091622</td>\n",
       "      <td>0.292085</td>\n",
       "      <td>0.135371</td>\n",
       "      <td>0.091622</td>\n",
       "      <td>20</td>\n",
       "      <td>22931</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>22931</td>\n",
       "      <td>4.470172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.091970</td>\n",
       "      <td>0.091775</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>0.113585</td>\n",
       "      <td>0.091775</td>\n",
       "      <td>0.293568</td>\n",
       "      <td>0.135817</td>\n",
       "      <td>0.091775</td>\n",
       "      <td>21</td>\n",
       "      <td>24023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>24023</td>\n",
       "      <td>4.433527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.138344</td>\n",
       "      <td>0.092663</td>\n",
       "      <td>0.092613</td>\n",
       "      <td>0.203581</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.092613</td>\n",
       "      <td>0.295392</td>\n",
       "      <td>0.136791</td>\n",
       "      <td>0.092613</td>\n",
       "      <td>22</td>\n",
       "      <td>25115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>25115</td>\n",
       "      <td>4.397331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.138230</td>\n",
       "      <td>0.093144</td>\n",
       "      <td>0.093369</td>\n",
       "      <td>0.203809</td>\n",
       "      <td>0.114215</td>\n",
       "      <td>0.093369</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.137666</td>\n",
       "      <td>0.093369</td>\n",
       "      <td>23</td>\n",
       "      <td>26207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>26207</td>\n",
       "      <td>4.361687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_HR@5  val_NDCG@5  val_MRR@5  val_HR@10  val_NDCG@10  val_MRR@10  \\\n",
       "0   0.060105    0.041397   0.042704   0.087249     0.049956    0.042704   \n",
       "1        NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "2   0.084968    0.056759   0.056998   0.128536     0.070710    0.056998   \n",
       "3        NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "4   0.088504    0.058479   0.058949   0.133896     0.073000    0.058949   \n",
       "5        NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "6   0.096715    0.064412   0.065046   0.145187     0.079893    0.065046   \n",
       "7        NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "8   0.106182    0.070787   0.071798   0.160812     0.088318    0.071798   \n",
       "9        NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "10  0.110287    0.073709   0.075088   0.170849     0.093129    0.075088   \n",
       "11       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "12  0.119183    0.078556   0.078904   0.179859     0.097963    0.078904   \n",
       "13       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "14  0.121350    0.079945   0.080079   0.182140     0.099461    0.080079   \n",
       "15       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "16  0.123061    0.081673   0.082200   0.187500     0.102420    0.082200   \n",
       "17       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "18  0.127623    0.083857   0.083410   0.190579     0.104089    0.083410   \n",
       "19       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "20  0.127167    0.084411   0.084870   0.191492     0.105191    0.084870   \n",
       "21       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "22  0.129106    0.085237   0.085084   0.192860     0.105827    0.085084   \n",
       "23       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "24  0.129904    0.086361   0.086534   0.197993     0.108157    0.086534   \n",
       "25       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "26  0.132641    0.088013   0.087910   0.197879     0.109019    0.087910   \n",
       "27       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "28  0.133554    0.088775   0.088572   0.200958     0.110327    0.088572   \n",
       "29       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "30  0.134352    0.088238   0.087630   0.200730     0.109422    0.087630   \n",
       "31       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "32  0.135835    0.090100   0.089987   0.204151     0.111981    0.089987   \n",
       "33       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "34  0.137660    0.091827   0.091658   0.205064     0.113413    0.091658   \n",
       "35       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "36  0.137318    0.090868   0.090544   0.205520     0.112684    0.090544   \n",
       "37       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "38  0.138116    0.092159   0.092103   0.204836     0.113663    0.092103   \n",
       "39       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "40  0.136633    0.091512   0.091622   0.204266     0.113191    0.091622   \n",
       "41       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "42  0.138002    0.091970   0.091775   0.205292     0.113585    0.091775   \n",
       "43       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "44  0.138344    0.092663   0.092613   0.203581     0.113634    0.092613   \n",
       "45       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "46  0.138230    0.093144   0.093369   0.203809     0.114215    0.093369   \n",
       "47       NaN         NaN        NaN        NaN          NaN         NaN   \n",
       "\n",
       "    val_HR@20  val_NDCG@20  val_MRR@20  epoch   step  train_loss  \n",
       "0    0.142564     0.064117    0.042704      0   1091         NaN  \n",
       "1         NaN          NaN         NaN      0   1091    6.541750  \n",
       "2    0.183508     0.084537    0.056998      1   2183         NaN  \n",
       "3         NaN          NaN         NaN      1   2183    5.938770  \n",
       "4    0.197194     0.088956    0.058949      2   3275         NaN  \n",
       "5         NaN          NaN         NaN      2   3275    5.712047  \n",
       "6    0.217495     0.098070    0.065046      3   4367         NaN  \n",
       "7         NaN          NaN         NaN      3   4367    5.503188  \n",
       "8    0.240990     0.108425    0.071798      4   5459         NaN  \n",
       "9         NaN          NaN         NaN      4   5459    5.342911  \n",
       "10   0.250570     0.113162    0.075088      5   6551         NaN  \n",
       "11        NaN          NaN         NaN      5   6551    5.218508  \n",
       "12   0.264599     0.119274    0.078904      6   7643         NaN  \n",
       "13        NaN          NaN         NaN      6   7643    5.121842  \n",
       "14   0.265853     0.120499    0.080079      7   8735         NaN  \n",
       "15        NaN          NaN         NaN      7   8735    5.045141  \n",
       "16   0.269161     0.122952    0.082200      8   9827         NaN  \n",
       "17        NaN          NaN         NaN      8   9827    4.980723  \n",
       "18   0.272354     0.124685    0.083410      9  10919         NaN  \n",
       "19        NaN          NaN         NaN      9  10919    4.924483  \n",
       "20   0.277828     0.126913    0.084870     10  12011         NaN  \n",
       "21        NaN          NaN         NaN     10  12011    4.873684  \n",
       "22   0.275890     0.126771    0.085084     11  13103         NaN  \n",
       "23        NaN          NaN         NaN     11  13103    4.827008  \n",
       "24   0.280109     0.128744    0.086534     12  14195         NaN  \n",
       "25        NaN          NaN         NaN     12  14195    4.782851  \n",
       "26   0.284215     0.130767    0.087910     13  15287         NaN  \n",
       "27        NaN          NaN         NaN     13  15287    4.740730  \n",
       "28   0.283759     0.131186    0.088572     14  16379         NaN  \n",
       "29        NaN          NaN         NaN     14  16379    4.699575  \n",
       "30   0.287181     0.131147    0.087630     15  17471         NaN  \n",
       "31        NaN          NaN         NaN     15  17471    4.659648  \n",
       "32   0.290488     0.133739    0.089987     16  18563         NaN  \n",
       "33        NaN          NaN         NaN     16  18563    4.620633  \n",
       "34   0.293339     0.135651    0.091658     17  19655         NaN  \n",
       "35        NaN          NaN         NaN     17  19655    4.581921  \n",
       "36   0.293910     0.134906    0.090544     18  20747         NaN  \n",
       "37        NaN          NaN         NaN     18  20747    4.544464  \n",
       "38   0.294024     0.136175    0.092103     19  21839         NaN  \n",
       "39        NaN          NaN         NaN     19  21839    4.507083  \n",
       "40   0.292085     0.135371    0.091622     20  22931         NaN  \n",
       "41        NaN          NaN         NaN     20  22931    4.470172  \n",
       "42   0.293568     0.135817    0.091775     21  24023         NaN  \n",
       "43        NaN          NaN         NaN     21  24023    4.433527  \n",
       "44   0.295392     0.136791    0.092613     22  25115         NaN  \n",
       "45        NaN          NaN         NaN     22  25115    4.397331  \n",
       "46   0.296875     0.137666    0.093369     23  26207         NaN  \n",
       "47        NaN          NaN         NaN     23  26207    4.361687  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('logs/lightning_logs/version_1/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_field = 'user_id'\n",
    "iid_field = 'item_id'\n",
    "item_text_field = 'item_text'\n",
    "item_seq_field = 'interactions'\n",
    "inter_table = 'interactions'\n",
    "item_table = 'items'\n",
    "seq_len = 20\n",
    "\n",
    "MIND_configs = {\n",
    "    inter_table: {\n",
    "        'filepath': 'MIND-small/behaviors.csv',\n",
    "        'field_separator': '\\t',\n",
    "        'seq_separator': ' ',\n",
    "        'header': 0,\n",
    "        'usecols': ['userid', 'behaviors'],\n",
    "        'rename_cols': {\n",
    "            'userid': uid_field,\n",
    "            'behaviors': item_seq_field\n",
    "        },\n",
    "        'filed_type': {\n",
    "            'userid': str,\n",
    "            'behaviors': str\n",
    "            },\n",
    "        'token_seq_fields': [item_seq_field],\n",
    "        'max_item_seq_length': None,\n",
    "        'min_item_seq_length': 5,\n",
    "        },\n",
    "    item_table: {\n",
    "        'filepath': 'MIND-small/news.csv',\n",
    "        'field_separator': '\\t',\n",
    "        'header': 0,\n",
    "        'usecols': ['newid', 'title'],\n",
    "        'filed_type': {\n",
    "            'newid': str,\n",
    "            'title': str\n",
    "            },\n",
    "        'rename_cols': {\n",
    "            'newid': iid_field,\n",
    "            'title': item_seq_field\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  user_id                                       interactions\n",
    "0  U65916  [19012, 44697, 30555, 28950, 18562, 19292, 247...\n",
    "1  U49985  [33251, 34121, 32633, 9813, 23038, 7016, 9440,...\n",
    "2  U25550  [20620, 25940, 24563, 12976, 11791, 35050, 245...\n",
    "3  U19710  [30053, 3965, 35238, 29936, 35346, 26608, 1916...\n",
    "4  U38106                [17314, 18160, 27298, 44397, 39131]\n",
    "   item_id                                          item_text\n",
    "0        1  The Brands Queen Elizabeth, Prince Charles, an...\n",
    "1        2  Dispose of unwanted prescription drugs during ...\n",
    "2        3  The Cost of Trump's Aid Freeze in the Trenches...\n",
    "3        4  I Was An NBA Wife. Here's How It Affected My M...\n",
    "4        5  How to Get Rid of Skin Tags, According to a De..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        uid_field,\n",
    "        iid_field,\n",
    "        item_text_field,\n",
    "        item_seq_field,\n",
    "        inter_table,\n",
    "        item_table,\n",
    "        data_configs,\n",
    "        ) -> None:\n",
    "        self.uid_field = uid_field\n",
    "        self.iid_field = iid_field\n",
    "        self.item_text_field = item_text_field\n",
    "        self.item_seq_field = item_seq_field\n",
    "        self.inter_table = inter_table\n",
    "        self.item_table = item_table\n",
    "        self.data_configs = data_configs\n",
    "        self.lookup_df = self.load_data(data_configs)     \n",
    "\n",
    "        # self.drop_duplicates()\n",
    "        \n",
    "        item_token_id, item_id_token, item_id_text = self.map_item_ID()\n",
    "        self.item_token_id: dict = item_token_id\n",
    "        self.item_id_token: list = item_id_token\n",
    "        self.item_id_text: list = item_id_text\n",
    "        \n",
    "        _max = data_configs[self.inter_table]['max_item_seq_length']\n",
    "        _min = data_configs[self.inter_table]['min_item_seq_length']\n",
    "        self.filter_item_seq_by_num(_min, _max)\n",
    "        \n",
    "        self.train_data, self.valid_data, self.test_data = \\\n",
    "            self.ratio_split()\n",
    "        \n",
    "    @property\n",
    "    def min_item_seq_len(self):\n",
    "        return self.lookup_df[self.inter_table][self.item_seq_field].apply(len).min()\n",
    "    \n",
    "    @property\n",
    "    def max_item_seq_len(self):\n",
    "        return self.lookup_df[self.inter_table][self.item_seq_field].apply(len).max()\n",
    "    \n",
    "    def load_data(self, datatables_config):\n",
    "        lookup_df = {}\n",
    "        for table_name, cfg in self.data_configs.items():\n",
    "            lookup_df[table_name] = pd.read_csv(\n",
    "                cfg['filepath'],\n",
    "                delimiter=cfg['field_separator'],\n",
    "                header=cfg['header'],\n",
    "                usecols=cfg['usecols'],\n",
    "                dtype=cfg['filed_type'],\n",
    "                encoding='utf-8',\n",
    "                engine='python'\n",
    "            )\n",
    "            lookup_df[table_name].rename(columns=cfg['rename_cols'], inplace=True)\n",
    "            \n",
    "            if 'token_seq_fields' in cfg:\n",
    "                for field in cfg['token_seq_fields']:\n",
    "                    lookup_df[table_name][field] = \\\n",
    "                        [\n",
    "                            np.array(list(filter(None, seq.split(cfg['seq_separator']))))\n",
    "                            for seq in lookup_df[table_name][field].values\n",
    "                        ]\n",
    "        return lookup_df\n",
    "    \n",
    "    def drop_duplicates(self):\n",
    "        self.lookup_df[self.inter_table] = self.lookup_df[self.inter_table].drop_duplicates(\n",
    "            subset=[self.uid_field, self.item_seq_field]\n",
    "        )\n",
    "        self.lookup_df[self.item_table] = self.lookup_df[self.item_table].drop_duplicates(\n",
    "            subset=[self.iid_field]\n",
    "        )\n",
    "    \n",
    "    def filter_item_seq_by_num(self, _min, _max):\n",
    "        assert _min > 0, 'min_item_seq_length must be greater than 0'\n",
    "        if _min is not None and _max is not None:\n",
    "            _max = float('inf') if _max is None else _max\n",
    "            _min = 0 if _min is None else _min\n",
    "            self.lookup_df[self.inter_table] = \\\n",
    "                self.lookup_df[self.inter_table][\n",
    "                    self.lookup_df[self.inter_table][self.item_seq_field]\n",
    "                        .apply(lambda x: len(x) >= _min and len(x) <= _max)\n",
    "                    ]\n",
    "            \n",
    "    def map_item_ID(self):\n",
    "        item_tokens = [self.lookup_df[self.item_table][self.iid_field].values]\n",
    "        item_tokens.append(self.lookup_df[self.inter_table][self.item_seq_field].agg(np.concatenate))\n",
    "        split_point = np.cumsum(list(map(len, item_tokens)))[:-1]\n",
    "        item_tokens = np.concatenate(item_tokens)\n",
    "        \n",
    "        new_ids_list, mappings = pd.factorize(item_tokens)\n",
    "        [item_tab_new_ids, inter_tab_new_ids] = np.split(new_ids_list + 1, split_point)\n",
    "        item_id_token = np.array(['[PAD]'] + list(mappings))\n",
    "        item_token_id = {token: idx for idx, token in enumerate(item_id_token)}\n",
    "        \n",
    "        self.lookup_df[self.item_table][self.iid_field] = item_tab_new_ids\n",
    "        split_point = np.cumsum(self.lookup_df[self.inter_table][self.item_seq_field].agg(len))[:-1]\n",
    "        self.lookup_df[self.inter_table][self.item_seq_field] = np.split(inter_tab_new_ids, split_point)\n",
    "        \n",
    "        # item already sorted by id when performing factorize\n",
    "        item_id_text = self.lookup_df[item_table][item_seq_field].values\n",
    "        item_id_text = np.concatenate([['[PAD]'], item_id_text])\n",
    "        return item_token_id, item_id_token, item_id_text\n",
    "    \n",
    "    def ratio_split(self):\n",
    "        \"\"\" fixed ratio split (train:0.8, valid:0.1, test:0.1) \"\"\"\n",
    "        inter_table = self.lookup_df[self.inter_table]\n",
    "        train_data = inter_table.sample(frac=0.8)\n",
    "        rest_data = inter_table[~inter_table.index.isin(train_data.index)]\n",
    "        valid_data = rest_data.sample(frac=0.5)\n",
    "        test_data = rest_data[~rest_data.index.isin(valid_data.index)]\n",
    "        \n",
    "        train_data = train_data[item_seq_field].values\n",
    "        valid_data = valid_data[item_seq_field].values\n",
    "        test_data = test_data[item_seq_field].values\n",
    "        \n",
    "        return train_data, valid_data, test_data\n",
    "    \n",
    "    def convert_id_to_text(self, data):\n",
    "        item_seq_text = []\n",
    "        for seq in data:\n",
    "            item_seq_text.append(self.item_id_text[seq])\n",
    "        return np.array(item_seq_text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep = DataPreprocessor(uid_field, iid_field, item_text_field, item_seq_field, inter_table, item_table, MIND_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14167, 29018, 18810, 49172, 39770, 35654, 34987], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataprep.train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextSeqRecDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        seq_len,\n",
    "        padding_idx=0,\n",
    "        ):\n",
    "        self._len = len(data)\n",
    "        self.seq_len = seq_len\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item_seqs, self.targets = self._right_padding_left_trancate(data, self.seq_len)\n",
    "        self.seq_masks = self._get_masks(self.item_seqs)\n",
    "        \n",
    "    def _right_padding_left_trancate(self, data, seq_len):\n",
    "        \"\"\" Generate items seq like [1, 2, 3, 0 , 0] and targets like [2, 3, 4, 0, 0] \"\"\"\n",
    "        item_seqs = np.zeros((len(data), seq_len), dtype=np.int64)\n",
    "        targets = np.zeros((len(data), seq_len), dtype=np.int64)\n",
    "        for i, data in enumerate(data):\n",
    "            if len(data) > seq_len:\n",
    "                item_seqs[i] = data[-seq_len-1:-1]\n",
    "                targets[i] = data[-seq_len:]\n",
    "            else:\n",
    "                item_seqs[i, :len(data)-1] = data[:-1]\n",
    "                targets[i, :len(data)-1] = data[1:]\n",
    "                \n",
    "        return item_seqs, targets\n",
    "    \n",
    "    def _get_masks(self, data):\n",
    "        masks = np.zeros(data.shape, dtype=np.int32)\n",
    "        masks = np.where(data != self.padding_idx, True, False)\n",
    "        return masks\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item_seq = self.item_seqs[idx]\n",
    "        target = self.targets[idx]\n",
    "        seq_mask = self.seq_masks[idx]\n",
    "        return item_seq, target, seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextSeqRecDataset(dataprep.train_data, seq_len)\n",
    "valid_dataset = TextSeqRecDataset(dataprep.valid_data, seq_len)\n",
    "test_dataset = TextSeqRecDataset(dataprep.test_data, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, k, v = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 13])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import our library\n",
    "import torchmetrics\n",
    "\n",
    "# simulate a classification problem\n",
    "preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import RetrievalHitRate\n",
    "indexes = torch.tensor([[0, 0, 0, 0], [1, 1, 1, 1]])\n",
    "preds = torch.tensor([[0.2, 0.3, 0.5, 0.6], [0.1, 0.3, 0.5, 0.2]])\n",
    "target = torch.tensor([[True, False, False, False], [False, True, False, True]])\n",
    "hr2 = RetrievalHitRate(k=2)\n",
    "hr2(preds, target, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import RetrievalHitRate\n",
    "\n",
    "batch_size = 16\n",
    "vocab_size = len(dataprep.item_token_id)\n",
    "\n",
    "preds = torch.randn(batch_size, vocab_size).softmax(dim=-1)\n",
    "indexes = torch.arange(0, batch_size).reshape(-1, 1).expand(-1, vocab_size).to(preds.device) # (batch_size, vocab_size)\n",
    "target_id = torch.randint(0, vocab_size, (batch_size, 1)).to(preds.device) # (batch_size, 1)\n",
    "target = torch.zeros(batch_size, vocab_size, dtype=torch.bool).scatter_(1, target_id, 1).to(preds.device) # (batch_size, vocab_size)\n",
    "\n",
    "hr5 = RetrievalHitRate(k=5)\n",
    "hr10 = RetrievalHitRate(k=10)\n",
    "hr20 = RetrievalHitRate(k=20)\n",
    "\n",
    "print(\n",
    "    hr5(preds, target, indexes=indexes),\n",
    "    hr10(preds, target, indexes=indexes),\n",
    "    hr20(preds, target, indexes=indexes),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('metaseq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8b66000015b8efd7d9ea31334b2bca5fb97dc84b74673cbcc6bdd1713cb08e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
